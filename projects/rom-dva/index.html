<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Range of Motion Assessment using a Digital Voice Assistant | Hassam Khan Wazir </title> <meta name="author" content="Hassam Khan Wazir"> <meta name="description" content="This work proposes using a Digital Voice Assistant for Range of Motion measurement by utilizing 2D pose estimation techniques to estimate 3D limb pose for specific exercises."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.css" integrity="sha256-uRX+PiRTR4ysKFRCykT8HLuRCub26LgXJZym3Yeom1c=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/hassam_logo-70x70.png?06f221be7ddca9e40227d0c21ce304aa"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://hassamwazir.github.io/projects/rom-dva/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Range of Motion Assessment using a Digital Voice Assistant",
            "description": "This work proposes using a Digital Voice Assistant for Range of Motion measurement by utilizing 2D pose estimation techniques to estimate 3D limb pose for specific exercises.",
            "published": "November 22, 2024",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Hassam</span> Khan Wazir </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Range of Motion Assessment using a Digital Voice Assistant</h1> <p>This work proposes using a Digital Voice Assistant for Range of Motion measurement by utilizing 2D pose estimation techniques to estimate 3D limb pose for specific exercises.</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#joint-coordinates-estimation">Joint coordinates estimation</a> </div> <div> <a href="#results">Results</a> </div> </nav> </d-contents> <p><strong>Publication:</strong> (Wazir et al., 2022)<d-cite key="wazir2022dva"></d-cite></p> <h2 id="introduction">Introduction</h2> <p>Range of motion (ROM) is an important indicator of an individual’s physical health, and its degradation impacts their ability to perform activities of daily living. The elderly are particularly susceptible to mobility loss due to muscular decline, neuromuscular disorders, sedentary lifestyle, etc. Thus, they must undergo periodic ROM assessments to track their physical well-being and consult doctors for any decline in ROM. An at-home ROM assessment device can assist the elderly to self-perform ROM assessment and facilitate remote monitoring of and compliance to therapy. The pervasive adoption of digital voice assistants (DVAs), that include a monocular camera, offers an opportunity for at-home ROM assessment.</p> <p>In this project, we use the <a href="https://store.google.com/product/google_nest_hub_max?hl=en-US&amp;pli=1" rel="external nofollow noopener" target="_blank">Google Nest Hub Max</a>, a DVA with a monocular camera, to measure the range of motion of the shoulder and elbow joints. The system employs the MediaPipe library to perform 2D pose estimation and uses the joint coordinates to find the 3D pose of the limb using a 2D projection method. The system is validated by comparing the results with a 3D human model performing various shoulder and elbow exercises in a virtual environment. Next, for further validation, a neurologically intact individual performs the same exercises and the results of the proposed system are compared with the results from a markerless optical motion capture system (<a href="https://en.wikipedia.org/wiki/Kinect" rel="external nofollow noopener" target="_blank">Kinect</a>). The <a href="https://en.wikipedia.org/wiki/Bland%E2%80%93Altman_plot" rel="external nofollow noopener" target="_blank">Bland-Altman limits of agreement (LOA)</a> are computed and provided for the two sets of comparisons. The results demonstrate the feasibility of the proposed system in providing reliable ROM measurements using a DVA and suggest possible enhancements. Figure 1 shows the system architecture.</p> <p align="center"> <img src="/assets/img/projects/rom-dva/system-architecture.png" alt="Overview of the proposed system." width="600px"> <br> <em>Figure 1: Overview of the proposed system.</em> </p> <h2 id="joint-coordinates-estimation">Joint coordinates estimation</h2> <p>To estimate the joint coordinates, we use the <a href="https://ai.google.dev/edge/mediapipe/solutions/guide" rel="external nofollow noopener" target="_blank">MediaPipe library</a>, which provides a 2D pose estimation model. The model detects 33 keypoints, including the shoulder, elbow, and wrist joints. The 2D coordinates of these keypoints are used to estimate the 3D pose of the limb using a 2D projection method. The 3D pose estimation is performed for the shoulder and elbow joints, and the range of motion is calculated based on the estimated joint angles.</p> <p align="center"> <img src="/assets/img/projects/rom-dva/joint-positions.png" alt="Figure. 2: Joint positions obtained from the MediaPipe and the vectors used to compute the joint angles: \(ˆ·\) and \(~·\) denote points and vectors, respectively." width="600px"> <br> <em>Figure. 2: Joint positions obtained from the MediaPipe and the vectors used to compute the joint angles: \(\,\hat{\cdot}\) and \(\,\vec{\cdot}\) denote points and vectors, respectively.</em> </p> <p>\begin{equation} a_r = \frac{A_{R_{avg}}}{T_{N_{avg}}} \quad \text{and} \quad f_r = \frac{F_{R_{avg}}}{T_{N_{avg}}} \end{equation}</p> <p><strong>Calculation step</strong>: We now determine the shoulder and elbow angles corresponding to various ROM exercises. We begin by noting that for two arbitrary vectors \(\tilde{v}_i = \hat{y}_i − \hat{x}_i, i = 1, 2\), the point of projection \(\hat{p}\) of the vector \(\tilde{v}_2\) on the vector \(\tilde{v}_1\) is given by</p> <p>\begin{equation} \label{eqn:eq_proj} \hat{p} = \text{proj}_{\vec{v_1}} \vec{v_2} + \hat{x_1} = \left( \frac{\vec{v_1} \cdot \vec{v_2}}{||\vec{v_1}||^2} \right) \vec{v_1} + \hat{x_1} \end{equation}</p> <p>Using (\ref{eqn:eq_proj}), we can now determine the following quantities: <em>(i)</em> the vertical and horizontal projections of the elbow \(\hat{E}_R\) on the base vector \(\vec{S}_B\) and the trunk vector \(\vec{T}_N\), denoted as \(\hat{E}_x\) and \(\hat{E}_y\), respectively; <em>(ii)</em> the vertical and horizontal projections of the wrist \(\hat{W}_R\) on \(\vec{S}_B\) and \(\vec{T}_N\), denoted as \(\hat{W}_x\) and \(\hat{W}_y\), respectively; and <em>(iii)</em> the vertical projection of the shoulder \(\hat{S}_R\) on \(\vec{S}_B\), denoted as \(\hat{S}_{x}\). See Figure 2 that shows the projections \(\hat{E}_x\), \(\hat{E}_y\), \(\hat{W}_x\), \(\hat{W}_y\), and \(\hat{S}_{x}\) for the right arm.</p> <p>It can be shown that for a 2D projection of a vector rotating inside a sphere with radius equal to the length of the rotating vector, the change in the distance from the vertical projection point of a vector (\(\hat{E}_y\) or \(\hat{W}_y\)) to \(\hat{S}_M\) is directly proportional to \(\cos({\theta})\). Thus, \(\theta\) can be calculated for the shoulder abduction-adduction and flexion-extension exercises as shown in (\ref{eqn:ROM_angles_theta_phi}). With the user at a constant distance from the DVA camera and when \(\theta = 90^\circ\), \(\phi\) can similarly be calculated as shown in (\ref{eqn:ROM_angles_theta_phi}). For the shoulder internal-external rotation exercise, let the upper arm point downwards (i.e., \(\theta = 0^\circ\)), and flex the elbow to \(90^\circ\) (i.e., elbow angle \(\alpha = 90^\circ\)). Then the internal-external rotation (i.e., shoulder angle \(\psi\)) can be computed as shown in (\ref{eqn:ROM_angles_psi_alpha}). Finally, for the elbow flexion-extension exercise, the arm is kept parallel to the camera image plane (i.e., \(\phi=0^\circ\)) and the elbow angle \(\alpha\), between the upper arm \(\vec{U}_R\) and forearm \(\vec{F}_R\) is calculated as shown in (\ref{eqn:ROM_angles_psi_alpha}).</p> <p>\begin{equation} \label{eqn:ROM_angles_theta_phi} \theta = \cos^{-1} \left( \frac{\hat{W_y} - \hat{S_M}}{T_{N_{avg}} a_r} \right), \quad \phi = \cos^{-1} \left( \frac{\hat{W_x} - \hat{S_x}}{T_{N_{avg}} a_s} \right), \end{equation}</p> <p>\begin{equation} \label{eqn:ROM_angles_psi_alpha} \psi = \cos^{-1} \left( \frac{\hat{W_x} - \hat{E_x}}{T_{N_{avg}} f_r} \right), \quad \alpha = \cos^{-1} \left( \frac{\vec{U_R} \cdot \vec{F_R}}{||\vec{U_R}|| ||\vec{F_R}||} \right) \end{equation}</p> <h2 id="results">Results</h2> <p>The results from the proposed method are compared to the ground truth using the Bland-Altman test to find the limits of agreement (LOA). Figure 3 and Table I show the LOA for various exercises. The LOA for exercise 2 is seen to be higher than for other exercises. This is explained by the arm motion out of the frontal plane for exercise 2, where the lack of depth information causes the proposed approach to be degraded especially near the extreme angles \((\theta = 0^\circ \text{ and } \theta = 180^\circ)\). In exercise 3, a similar effect is seen at \((\phi = 0^\circ)\), but since the angle never reaches \((\phi = 180^\circ)\), the LOA is lower in this case. In exercise 4, since only the forearm moves out of the frontal plane, the lack of depth estimation does not degrade the corresponding ROM estimate excessively.</p> <p>Figure. 3 and Table I also show the LOA between the proposed method vs. Kinect. The LOA data has larger values for comparison with Kinect in contrast to the ground truth. One reason for this may be that the camera sensor suffers from noise. Next, for exercise 1, the large LOA against Kinect may arise from the discrepancy in the data for the low values of shoulder elevation angles, which are normally the resting position of the arm and may not be significant for one’s ability to perform activities of daily living. For the larger shoulder elevation angles, the data from the proposed system closely follows the data from the Kinect. For exercise 2, the large value of LOA can be attributed to the discrepancy in the data for the low and high values of shoulder elevation angles, where the Kinect measurements may suffer due to only small changes in depth. For exercise 3, the large value of LOA can be attributed to data discrepancy for \((\phi = 90^\circ)\) where the Kinect sensor suffers from occlusion of the elbow joint. For exercise 4, the large LOA value may arise from the moving average process used in the proposed method that reduces the slope of the motion trajectory as the arm switches from internal to external rotation. While this does not affect the peak values, a reduction in the moving average window size is found to improve the LOA. Finally, for exercise 5, the large LOA against Kinect may be caused by the pose prediction uncertainty from the MediaPipe and the Kinect.</p> <p><strong>TABLE I:</strong> Limits of agreement for shoulder (S) and elbow (E) exercises.</p> <table> <thead> <tr> <th style="text-align: center">No.</th> <th style="text-align: left">Exercise</th> <th style="text-align: center">vs. Synthetic data</th> <th style="text-align: center">vs. Kinect</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">1</td> <td style="text-align: left">Shoulder abduction-adduction</td> <td style="text-align: center">±4.3°</td> <td style="text-align: center">±8.8°</td> </tr> <tr> <td style="text-align: center">2</td> <td style="text-align: left">Shoulder flexion-extension</td> <td style="text-align: center">±7.1°</td> <td style="text-align: center">±12.6°</td> </tr> <tr> <td style="text-align: center">3</td> <td style="text-align: left">Shoulder plane angle</td> <td style="text-align: center">±3.3°</td> <td style="text-align: center">±12.1°</td> </tr> <tr> <td style="text-align: center">4</td> <td style="text-align: left">Shoulder internal-external rotation</td> <td style="text-align: center">±4.3°</td> <td style="text-align: center">±15.6°</td> </tr> <tr> <td style="text-align: center">5</td> <td style="text-align: left">Elbow flexion-extension</td> <td style="text-align: center">±2.9°</td> <td style="text-align: center">±7.2°</td> </tr> </tbody> </table> <p></p> <p><em>(Python programming, MediaPipe, Data acquisition, processing, and visualization)</em></p> <p><strong>Tech</strong>: Python, MATLAB, Web sockets, IFTTT</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/projects/rom-dva/rom-dva.bib"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Hassam Khan Wazir. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-GBHVTBHLJ9"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-GBHVTBHLJ9");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"Publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of projects that I have worked on over the years.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-teaching",title:"Teaching",description:"These are the courses I have taught over the years.",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"nav-cv",title:"CV",description:"This is my Curriculum Vitae. You can download it by clicking the button on the top right.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-nyu-hpc-setup",title:"NYU HPC Setup",description:"A guide for logging into the NYU HPC cluster and streamlining that process.",section:"Posts",handler:()=>{window.location.href="/blog/2023/nyu-hpc-setup/"}},{id:"post-the-z-domain-transfer-function-and-the-bilinear-transformation",title:"The z-domain transfer function and the Bilinear transformation.",description:"Understanding the z-domain transfer function and the bilinear transformation.",section:"Posts",handler:()=>{window.location.href="/blog/2020/imr-zdomain/"}},{id:"post-classical-controllers-p-i-d",title:"Classical Controllers (P, I, D)",description:"In this post, we will discuss the common types of controllers used in classical control systems.",section:"Posts",handler:()=>{window.location.href="/blog/2020/controls-controllers/"}},{id:"post-system-configuration-transfer-function-laplace-transform-and-system-order",title:"System Configuration, Transfer Function, Laplace Transform, and System Order.",description:"Understanding what a system is, its configuration, transfer function, Laplace transform, and system order.",section:"Posts",handler:()=>{window.location.href="/blog/2020/controls-system-config/"}},{id:"news-successfully-defended-my-ph-d-dissertation",title:"Successfully defended my Ph.D. dissertation! \ud83c\udf93",description:"",section:"News",handler:()=>{window.location.href="/news/phd-defense/"}},{id:"news-started-a-research-scientist-position-at-nyu-tandon-school-of-engineering-computer",title:'Started a Research Scientist Position at NYU Tandon School of Engineering! <img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20">',description:"",section:"News"},{id:"news-presented-a-poster-at-the-2024-ieee-engineering-medicine-and-biology-conference",title:"Presented a Poster at the 2024 IEEE Engineering Medicine and Biology Conference \ud83d\udcca...",description:"",section:"News",handler:()=>{window.location.href="/news/embc/"}},{id:"projects-wireless-earphone-based-monitoring-of-breathing-exercises",title:"Wireless Earphone-based Monitoring of Breathing Exercises",description:"This work proposes using commodity earphones for real-time breathing channel and phase detection for breathing therapy compliance monitoring.",section:"Projects",handler:()=>{window.location.href="/projects/audio-breathing/"}},{id:"projects-remote-control-of-a-dialysis-machine-using-a-human-robot-interaction",title:"Remote Control of a Dialysis Machine using a Human-Robot Interaction",description:"In this work we propose an emergency, non-invasive remote monitoring and control response system to retrofit dialysis machines with robotic manipulators for safely supporting the treatment of patients with acute kidney disease.",section:"Projects",handler:()=>{window.location.href="/projects/covid-project/"}},{id:"projects-embodied-agents-using-a-turtlebot3",title:"Embodied Agents using a Turtlebot3",description:"Understanding embodied agents with a Turtlebot3 and ROS.",section:"Projects",handler:()=>{window.location.href="/projects/robot-llm/"}},{id:"projects-using-capability-maps-and-virtual-reality-for-occupational-therapy",title:"Using Capability Maps and Virtual Reality for Occupational Therapy",description:"This work proposes using arm kinematic modeling and capability maps to allow a VR system to understand a user\u2019s physical capability and limitation.",section:"Projects",handler:()=>{window.location.href="/projects/rom-capability/"}},{id:"projects-range-of-motion-assessment-using-a-digital-voice-assistant",title:"Range of Motion Assessment using a Digital Voice Assistant",description:"This work proposes using a Digital Voice Assistant for Range of Motion measurement by utilizing 2D pose estimation techniques to estimate 3D limb pose for specific exercises.",section:"Projects",handler:()=>{window.location.href="/projects/rom-dva/"}},{id:"projects-wearable-pendant-sensor-for-therapy-compliance",title:"Wearable Pendant Sensor for Therapy Compliance",description:"A wearable pendant sensor to monitor compliance with range of motion lymphatic health exercise",section:"Projects",handler:()=>{window.location.href="/projects/rom-wps/"}},{id:"projects-a-minimalistic-puppeteering-robot",title:"A minimalistic puppeteering robot",description:"A minimalistic puppeteering robot that can convey human emotions. The robot was featured in the theatrical production Rescate at the La Moneda Cultural Center, Chile.",section:"Projects",handler:()=>{window.location.href="/projects/speaker-project/"}},{id:"projects-simulating-a-swarm-of-robots-in-gazebo",title:"Simulating a Swarm of Robots in Gazebo",description:"In this project, I simulated a swarm of robots in Gazebo. The robots were controlled using a decentralized control algorithm that allowed them to move in a formation while avoiding obstacles.",section:"Projects",handler:()=>{window.location.href="/projects/swarm-simulation/"}},{id:"projects-werable-inertial-sensors-for-exergames",title:"Werable Inertial Sensors for Exergames",description:"This work presents the design and development of wearable inertial sensors (WIS) for real-time simultaneous triplanar motion capture of the upper extremity.",section:"Projects",handler:()=>{window.location.href="/projects/wise/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%68%61%73%73%61%6D.%77%61%7A%69%72@%6E%79%75.%65%64%75","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0003-4930-3259","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=hBetThYAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/hassamwazir","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/hassam-wazir","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>